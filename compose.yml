services:

  docs:
    container_name: docs
    image: nginx
    ports:
      - "80:80"
    volumes:
      - "./nginx/html:/usr/share/nginx/html:ro"

  my-kafka:
    container_name: kafka
    image: apache/kafka
    ports:
      - 9092:9092
  
  spark-master:
    container_name: spark-master
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-master.sh"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  spark-worker-01:
    container_name: spark-worker-01
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-slave.sh", "spark://master:7077"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    depends_on:
      - spark-master
    ports:
      - 4041:4040
      - "6066"
      - "7077"
      - 8081:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  spark-worker-02:
    container_name: spark-worker-02
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-slave.sh", "spark://master:7077"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    depends_on:
      - spark-master
    ports:
      - 4042:4040
      - "6066"
      - "7077"
      - 8082:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  jupyter:
    container_name: jupyter
    image: arjones/pyspark:2.4.5
    restart: always
    environment:
      MASTER: spark://master:7077
    depends_on:
      - spark-master
    ports:
      - "8888:8888"
    volumes:
      - ./jupyter/notebook:/notebook
      - ./dataset:/dataset
      - ./code:/app
